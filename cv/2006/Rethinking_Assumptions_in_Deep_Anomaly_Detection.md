# [Rethinking Assumptions in Deep Anomaly Detection](https://arxiv.org/pdf/2006.00339.pdf)

異常検知(AD)は、分類問題(正常 vs 異常)の問題にも置き換えられる。それを異常とみなすほどのデータセットを十分に取得できないため、一般的には教師なしの手法で扱う。ImageNetの最近のADベンチマークでは、通常のサンプルと少しのランダムな自然画像を区別するようにトレーニングされた分類器は、現存の最新の深層AD手法を上回ることを示した。

## アプローチ

+ 教師なし
  ADにおける一般的なアプローチ (異常データを使用しない)
+ 半教師ありOE
  異常データをデータセットに組み込んだ教師なしAD　（距離基準）
+ 教師ありOE
  異常データと正常データを分類することでADをする

 画像AD問題では、インターネット上にあるランダムな自然画像のうち、公称画像ではない可能性の高いものが無制限に存在し、そのようなデータを利用して教師なし手法を改善すべき。このようなデータを利用することをOE（outlier exposure）と呼んでいます。

 OE；異常のデータではないが、正解ではないデータのこと?

 例えばMNISTの場合、EMNIST-Lettersデータセットを使うこと.

 半教師ありOEは、2次元にマッピングするなど、0,1に分離するわけではない。=>教師なしということ？？


## 概要

ADで提示される異常は「異常」を完全に特徴づけるものではない可能性が高いため、教師ありOEより、教師なしOEを用いることは理にかなっている。しかし、この論文では、画像のディープADが（OEの有無にかかわらず）教師なしアプローチを必要とするという仮定に異議を唱える実験結果を示します。

実験の説明がある〜=>結果的に、OEの有無に関わらず、ImageNetによる分類は、教師なしの全てのメソッドより優れていた。

### 直感と反する
  + Goodfellowらによる多数(数千)のサンプルは、データのクラスを理解する深い分類器のために必要
  + 異常は集中していないため、データで特徴づけることは本質的に困難

OEサンプルが少ない分類は深部ADでは効果がないはずであることを意味する。

### 古典的ADと深層画像AD

違いは、複数の空間スケールでの情報が存在すること。OE画像には、異常の例として機能する様々なスケールの複数の特徴が含まれていることを仮定。

教師なしOEに対する教師ありOEの利点は、多くの空間スケールを網羅できるImageNetのデータセットでは、明白だが、CIFAR-10では網羅性が低下し、MNISTでは存在しない。また、ImageNetにおいてOE画像をわずかにぼかすと、小規模な特徴がなくなり、パフォーマンスが劣化する。

名目クラスとOEの例に十分なマルチスケール情報が含まれている場合の教師付きOEが有利で、マルチスケール情報が欠落しているか、またはOEサンプルが非常に少ない場合は教師なしOEが有利

OEデータ数が増えると、性能が同じくらいになる。

##　実験

結果的に面白いのは、スケールが変わらないMNISTは、どんなにOEデータを加えても教師なしOEの性能の方が良いこと。




  
